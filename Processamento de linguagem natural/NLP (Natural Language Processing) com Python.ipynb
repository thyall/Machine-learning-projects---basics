{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP (Natural Language Processing) com Python\n",
    "\n",
    "Este é o notebook que acompanha o de vídeo de NLP!\n",
    "\n",
    "Nesta palestra discutiremos uma visão geral de processamento de linguagem natural, que basicamente consiste em combinar técnicas de Machine Learning com texto e usando matemática e estatísticas para obter esse texto em um formato que os algoritmos de aprendizado de máquina possam entender!\n",
    "\n",
    "Depois de concluir esta palestra, você terá um projeto usando alguns dados de texto da Yelp!\n",
    "    \n",
    "** Requisitos: você precisará ter NLTK instalado, além de baixar o corpus para palavras-passe. Para baixar tudo com uma instalação conda, execute a célula abaixo. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtendo os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos um conjunto de dados da [UCI](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection)! Este conjunto de dados já está localizado na pasta para esta seção."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O arquivo que estamos usando contém uma coleção de mais de 5 mil mensagens SMS. Você pode checar o arquivo ** readme ** para obter mais informações.\n",
    "\n",
    "Vamos continuar usando Rstrip() e uma lista de compreensão para obter uma lista de todas as linhas de mensagens de texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5574\n"
     ]
    }
   ],
   "source": [
    "messages = [line.rstrip() for line in open('smsspamcollection/SMSSpamCollection')]\n",
    "print(len(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma coleção de textos também é chamado às vezes de \"corpus\". Vamos imprimir as dez primeiras mensagens e numerá-las usando ** enumerate **:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "\n",
      "1 ham\tOk lar... Joking wif u oni...\n",
      "\n",
      "\n",
      "2 spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n",
      "\n",
      "3 ham\tU dun say so early hor... U c already then say...\n",
      "\n",
      "\n",
      "4 ham\tNah I don't think he goes to usf, he lives around here though\n",
      "\n",
      "\n",
      "5 spam\tFreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, Â£1.50 to rcv\n",
      "\n",
      "\n",
      "6 ham\tEven my brother is not like to speak with me. They treat me like aids patent.\n",
      "\n",
      "\n",
      "7 ham\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\n",
      "\n",
      "\n",
      "8 spam\tWINNER!! As a valued network customer you have been selected to receivea Â£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
      "\n",
      "\n",
      "9 spam\tHad your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message_no, message in enumerate(messages[:10]):\n",
    "    print(message_no, message)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devido ao espaçamento, podemos dizer que este é um arquivo [TSV](http://en.wikipedia.org/wiki/Tab-separated_values) (\"valores separados por tabulação\"), onde a primeira coluna é uma etiqueta dizendo se a a mensagem dada é uma mensagem normal (comumente conhecida como \"ham\") ou \"spam\". A segunda coluna é a própria mensagem. (Notemos que nossos números não fazem parte do arquivo, eles são apenas do ** enumerate **).\n",
    "\n",
    "Usando estes exemplos de ham e spam rotulados, iremos treinar um modelo de aprendizado de máquina para aprender a discriminar entre ham / spam automaticamente **. Então, com um modelo treinado, poderemos ** classificar mensagens arbitrárias sem letras ** como ham ou spam.\n",
    "\n",
    "A partir da documentação oficial SciKit Learn, podemos visualizar nosso processo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='http://www.astroml.org/sklearn_tutorial/_images/plot_ML_flow_chart_3.png' width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em vez de analisar TSV manualmente usando o Python, podemos aproveitar os pandas! Vamos continuar e importá-lo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use **read_csv** and make note of the **sep** argument, we can also specify the desired column names by passing in a list of *names*.\n",
    "\n",
    "Usaremos ** read_csv ** e ajustaremos o argumento** sep **. Também podemos especificar os nomes das colunas desejadas passando em uma lista de * nomes *."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = pd.read_csv('smsspamcollection/SMSSpamCollection', sep='\\t',\n",
    "                           names=[\"label\", \"message\"])\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de dados exploratória\n",
    "\n",
    "Vamos verificar algumas das estatísticas com plots e os métodos incorporados ao pandas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                 message\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos usar ** groupby ** e usar describe() nos rótulos, desta forma podemos começar a pensar sobre os recursos que separam ham e spam!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ham</td>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>spam</td>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      message                                                               \n",
       "        count unique                                                top freq\n",
       "label                                                                       \n",
       "ham      4825   4516                             Sorry, I'll call later   30\n",
       "spam      747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao continuar nossa análise, queremos começar a pensar nos parâmetrs que usaremos. Isso acompanha a idéia geral de [engenharia de parâmetros](https://en.wikipedia.org/wiki/Feature_engineering). A engenharia de recursos é uma parte muito grande da detecção de spam em geral. Encorajo você a ler sobre o assunto!\n",
    "\n",
    "Vamos criar uma nova coluna para detectar o tamanho das mensagens de texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1   ham                      Ok lar... Joking wif u oni...      29\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3   ham  U dun say so early hor... U c already then say...      49\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['length'] = messages['message'].apply(len)\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização de dados\n",
    "Vamos visualizar isso! Vamos fazer as importações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a6ac338080>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "sns.set_style(\"darkgrid\")\n",
    "messages['length'].plot(bins=80, kind='hist') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jogue com o tamanho da variável bin! Parece que o comprimento do texto pode ser uma boa característica para pensar! Vamos tentar explicar também o por que do eixo x ir até o comprimento 1000. Isso deve significar que há uma mensagem muito longa!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5572.000000\n",
       "mean       80.489950\n",
       "std        59.942907\n",
       "min         2.000000\n",
       "25%        36.000000\n",
       "50%        62.000000\n",
       "75%       122.000000\n",
       "max       910.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.length.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "910 caracteres! Vamos usar o mascaramento para encontrar esta mensagem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"For me the love should start with attraction.i should feel that I need her every time around me.she should be the first thing which comes in my thoughts.I would start the day and end it with her.she should be there every time I dream.love will be then when my every breath has her name.my life should happen around her.my life will be named to her.I would cry for her.will give all my happiness and take all her sorrows.I will be ready to fight with anyone for her.I will be in love when I will be doing the craziest things for her.love will be when I don't have to proove anyone that my girl is the most beautiful lady on the whole planet.I will always be singing praises for her.love will be when I start up making chicken curry and end up makiing sambar.life will be the most beautiful then.will get every morning and thank god for the day because she is with me.I would like to say a lot..will tell later..\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[messages['length'] == 910]['message'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que temos algum tipo de texto enviado por um Romeu! Mas vamos nos concentrar na idéia de tentar ver se o comprimento da mensagem é uma característica distintiva entre ham e spam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x000001A6AC6FF240>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x000001A6AC95F898>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages.hist(column='length', by='label', bins=50,figsize=(12,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muito interessante! Com apenas EDA básica, conseguimos descobrir uma tendência de que as mensagens de spam tendem a ter mais caracteres. (Desculpe, Romeu!)\n",
    "\n",
    "Agora vamos começar a processar os dados para que possamos eventualmente usá-lo com o SciKit Learn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré Processamento de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso principal problema com nossos dados é que está tudo em formato de texto (strings). Os algoritmos de classificação que aprendemos até agora precisam de algum tipo de vetor de características numéricas para realizar a tarefa de classificação. Na verdade, existem muitos métodos para converter um textos em um formato vetorial. O mais simples é a abordagem [bag-of-words](http://en.wikipedia.org/wiki/Bag-of-words_model), onde cada palavra única em um texto será representada por um número.\n",
    "\n",
    "\n",
    "Nesta seção, converteremos as mensagens brutas (seqüência de caracteres) em vetores (seqüências de números).\n",
    "\n",
    "Como primeiro passo, vamos escrever uma função que dividirá uma mensagem em suas palavras individuais e retornará uma lista. Também removeremos palavras muito comuns, ('' '', 'a', etc.). Para fazer isso, iremos aproveitar a biblioteca NLTK. É praticamente a biblioteca padrão em Python para processar texto e tem muitos recursos úteis. Nós só usaremos alguns dos básicos aqui.\n",
    "\n",
    "Vamos criar uma função que processará a string na coluna da mensagem, então podemos usar ** apply() ** do pandas para processar todo o texto no DataFrame.\n",
    "\n",
    "Primeira eliminamos a pontuação. Podemos aproveitar a biblioteca incorporada ** string ** do Python para obter uma lista rápida de todas as possíveis pontuações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "mess = 'Sample message! Notice: it has punctuation.'\n",
    "\n",
    "# Checa para retirar pontuações\n",
    "nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "# Junta novamente os caracteres para formar um string e não uma lista\n",
    "nopunc = ''.join(nopunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos ver como remover stopwords. Podemos importar uma lista de stopwords do inglesas da NLTK (verifique a documentação para mais idiomas e informações)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')[0:10] # Mostre alguns exemplos de stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sample', 'message', 'Notice', 'it', 'has', 'punctuation']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nopunc.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora remova as stopwords\n",
    "clean_mess = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sample', 'message', 'Notice', 'punctuation']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_mess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, coloquemos esses dois juntos em uma função para aplicá-lo ao nosso DataFrame mais tarde:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    # Retira pontuações\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Junta-os para formar strings\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Remove as stopwords\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui está o DataFrame original novamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1   ham                      Ok lar... Joking wif u oni...      29\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3   ham  U dun say so early hor... U c already then say...      49\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos \"tokenizar\" essas mensagens. Tokenização é apenas o termo usado para descrever o processo de conversão das cadeias de texto normais em uma lista de tokens (palavras que realmente queremos).\n",
    "\n",
    "Vamos ver um exemplo de saída na coluna:\n",
    "\n",
    "**Nota:**\n",
    "Podemos obter alguns avisos ou erros para símbolos que não contamos ou que não estavam no Unicode (como um símbolo de libra britânica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Go, jurong, point, crazy, Available, bugis, n...\n",
       "1                       [Ok, lar, Joking, wif, u, oni]\n",
       "2    [Free, entry, 2, wkly, comp, win, FA, Cup, fin...\n",
       "3        [U, dun, say, early, hor, U, c, already, say]\n",
       "4    [Nah, dont, think, goes, usf, lives, around, t...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifique para ver se está funcionando\n",
    "messages['message'].head(5).apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1   ham                      Ok lar... Joking wif u oni...      29\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3   ham  U dun say so early hor... U c already then say...      49\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostra o DataFrame original\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuação da normalização\n",
    "\n",
    "Há muitas maneiras de continuar normalizando esse texto. Como [Stemming] (https://en.wikipedia.org/wiki/Stemming) ou distinguindo por [parte do discurso] (http://www.nltk.org/book/ch05.html).\n",
    "\n",
    "O NLTK possui muitas ferramentas integradas e UMA excelente documentação em muitos destes métodos. Às vezes, eles não funcionam bem para mensagens de texto devido ao modo como muitas pessoas tendem a usar abreviaturas ou taquigrafia:\n",
    "    \n",
    "    \n",
    "Alguns métodos de normalização de texto terão problemas com este tipo de taquigrafia e, portanto, deixarei você para explorar esses métodos mais avançados através do [NLTK book online](http://www.nltk.org/book/).\n",
    "\n",
    "Por enquanto, apenas nos concentraremos EMs converter nossa lista de palavras para um vetor real que o SciKit-Learn pode usar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vetorização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos as mensagens como listas de tokens (também conhecido como [lemmas](http://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html)) e agora nós precisa converter cada uma dessas mensagens em um vetor com o qual os modelos de algoritmo do SciKit Learn podem funcionar.\n",
    "\n",
    "Agora, converteremos cada mensagem, representada como uma lista de tokens (lemmas) acima, em um vetor que os modelos de aprendizagem de máquinas podem entender.\n",
    "\n",
    "Vamos fazer isso em três etapas usando o modelo bag-of-words:\n",
    "\n",
    "1. Contar quantas vezes ocorre uma palavra em cada mensagem (conhecida como freqüência de termo)\n",
    "\n",
    "2. Pesar as contagens, de modo que tokens freqüentes recebem menor peso (freqüência inversa do documento)\n",
    "\n",
    "3. Normalize os vetores para o comprimento da unidade, para abstrair do comprimento do texto original (norma L2)\n",
    "\n",
    "Vamos começar o primeiro passo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada vetor terá tantas dimensões quanto houverem palavras únicas no corpo do SMS. Em primeiro lugar usaremos o ** CountVectorizer ** do SciKit Learn **. Este modelo converterá uma coleção de documentos de texto em uma matriz de contagem de token.\n",
    "\n",
    "Podemos imaginar isso como uma matriz bidimensional. Onde a dimensão 1 é o vocabulário inteiro (1 linha por palavra) e a outra dimensão são os documentos reais, neste caso uma coluna por mensagem de texto.\n",
    "\n",
    "Por exemplo:\n",
    "\n",
    "<table border = “1“>\n",
    "<tr>\n",
    "<th></th> <th>Message 1</th> <th>Message 2</th> <th>...</th> <th>Message N</th> \n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word 1 Count</b></td><td>0</td><td>1</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word 2 Count</b></td><td>0</td><td>0</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>...</b></td> <td>1</td><td>2</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word N Count</b></td> <td>0</td><td>1</td><td>...</td><td>1</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Uma vez que há tantas mensagens, podemos esperar muitos elementos zerados. Por isso, o SciKit Learn emitirá uma [Matriz Esparsa](https://en.wikipedia.org/wiki/Sparse_matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Há muitos argumentos e parâmetros que podem ser passados para o CountVectorizer. Neste caso, vamos especificar o ** analyzer ** para ser nossa própria função previamente definida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11425\n"
     ]
    }
   ],
   "source": [
    "# Talvez demor um pouco\n",
    "bow_transformer = CountVectorizer(analyzer=text_process).fit(messages['message'])\n",
    "\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos pegar uma mensagem de texto e obter suas contagens de bag-of-words como um vetor, colocando em uso o nosso novo `bow_transformer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U dun say so early hor... U c already then say...\n"
     ]
    }
   ],
   "source": [
    "message4 = messages['message'][3]\n",
    "print(message4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vejamos sua representação vetorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4068)\t2\n",
      "  (0, 4629)\t1\n",
      "  (0, 5261)\t1\n",
      "  (0, 6204)\t1\n",
      "  (0, 6222)\t1\n",
      "  (0, 7186)\t1\n",
      "  (0, 9554)\t2\n",
      "(1, 11425)\n"
     ]
    }
   ],
   "source": [
    "bow4 = bow_transformer.transform([message4])\n",
    "print(bow4)\n",
    "print(bow4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso significa que existem sete palavras únicas na mensagem número 4 (depois de remover stopwords). Dois deles aparecem duas vezes, o resto apenas uma vez. Vamos em frente e verifique e confirme quais aparecem duas vezes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U\n",
      "say\n"
     ]
    }
   ],
   "source": [
    "print(bow_transformer.get_feature_names()[4068])\n",
    "print(bow_transformer.get_feature_names()[9554])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, podemos usar **.transform ** em nosso objeto transformado Bag-of-Words (bow) e transformar todo o DataFrame de mensagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_bow = bow_transformer.transform(messages['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (5572, 11425)\n",
      "Amount of Non-Zero occurences:  50548\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Sparse Matrix: ', messages_bow.shape)\n",
    "print('Amount of Non-Zero occurences: ', messages_bow.nnz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "porcentagem de não zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0\n"
     ]
    }
   ],
   "source": [
    "sparsity = (100.0 * messages_bow.nnz / (messages_bow.shape[0] * messages_bow.shape[1]))\n",
    "print('sparsity: {}'.format(round(sparsity)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a contagem, o termo ponderação e normalização pode ser feito com [TF-IDF](http://en.wikipedia.org/wiki/Tf%E2%80%93idf), usando o `TfidfTransformer` do scikit-learn.\n",
    "\n",
    "____\n",
    "### Então, o que é TF-IDF?\n",
    "TF-IDF significa *term frequency-inverse document frequency* (frequência do termo - inverso da frequência nos documentos), e o peso tf-idf é um peso freqüentemente usado na recuperação de informações e na mineração de texto. Esse peso é uma medida estatística usada para avaliar a importância de uma palavra em um documento, coleção ou corpus. A importância aumenta proporcionalmente ao número de vezes que uma palavra aparece no documento, mas é compensada pela freqüência da palavra no corpus. As variações do esquema de ponderação tf-idf são frequentemente utilizadas pelos motores de busca como uma ferramenta central na pontuação e classificação da relevância de um documento, dada uma consulta do usuário.\n",
    "\n",
    "Uma das funções de classificação mais simples é calculada somando o tf-idf para cada termo de consulta; Muitas funções de classificação mais sofisticadas são variantes desse modelo simples.\n",
    "\n",
    "Normalmente, o peso de tf-idf é composto por dois termos: o primeiro calcula a Freqüência do termo normalizada (TF), ou seja, o número de vezes que uma palavra aparece em um documento, dividido pelo número total de palavras nesse documento; O segundo termo é a Freqüência do Documento Inverso (IDF), calculado como o logaritmo do número de documentos no corpus dividido pela quantidade de documentos onde o termo específico aparece.\n",
    "\n",
    "** TF: Frequência do termo **, que mede a frequência com que ocorre um termo em um documento. Uma vez que cada documento é diferente em comprimento, é possível que um termo apareça muito mais vezes em documentos longos do que os mais curtos. Assim, o termo freqüência é freqüentemente dividido pelo comprimento do documento (também conhecido como o número total de termos no documento) como forma de normalização:\n",
    "\n",
    "* TF (t) = (Número de vezes que o termo t aparece em um documento) / (Número total de termos no documento). *\n",
    "\n",
    "** IDF: Freqüência do Documento Inverso **, que mede o quão importante é um termo. Ao computar TF, todos os termos são considerados igualmente importantes. No entanto, é sabido que certos termos, como \"is\", \"of\", e \"that\", podem aparecer muitas vezes, mas têm pouca importância. Assim, precisamos pesar os termos freqüentes, enquanto aumentamos as raras, ao computar o seguinte:\n",
    "\n",
    "* IDF (t) = log_e (Número total de documentos / Número de documentos com termo t nele). *\n",
    "\n",
    "Veja abaixo um exemplo simples.\n",
    "\n",
    "**Exemplo:**\n",
    "\n",
    "Considere um documento contendo 100 palavras em que a palavra gato aparece 3 vezes.\n",
    "\n",
    "O termo frequência (isto é, tf) para gato é então (3/100) = 0,03. Agora, suponha que temos 10 milhões de documentos e a palavra gato aparece em mil desses. Então, a frequência inversa do documento (isto é, idf) é calculada como log (10 000 000/1000) = 4. Assim, o peso Tf-idf é o produto dessas quantidades: 0,03 * 4 = 0,12.\n",
    "____\n",
    "\n",
    "Avançemos e vejamos como podemos fazer isso no SciKit Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9554)\t0.5385626262927564\n",
      "  (0, 7186)\t0.4389365653379857\n",
      "  (0, 6222)\t0.3187216892949149\n",
      "  (0, 6204)\t0.29953799723697416\n",
      "  (0, 5261)\t0.29729957405868723\n",
      "  (0, 4629)\t0.26619801906087187\n",
      "  (0, 4068)\t0.40832589933384067\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "tfidf4 = tfidf_transformer.transform(bow4)\n",
    "print(tfidf4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos prosseguir e verificamos qual é o IDF (frequência do documento inverso) da palavra `` u '' e da palavra '' university ''?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2800524267409408\n",
      "8.527076498901426\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_transformer.idf_[bow_transformer.vocabulary_['u']])\n",
    "print(tfidf_transformer.idf_[bow_transformer.vocabulary_['university']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para transformar todo o bag-of-words em corpus TF-IDF de uma só vez:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 11425)\n"
     ]
    }
   ],
   "source": [
    "messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
    "print(messages_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Há muitas maneiras pelas quais os dados podem ser pré-processados e vetorizados. Essas etapas envolvem engenharia de recursos e construção de um \"pipeline\". Eu encorajo você a verificar a documentação do SciKit Learn sobre como lidar com dados de texto, bem como a ampla coleção de artigos e livros disponíveis sobre o tema geral da NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando um modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com mensagens representadas como vetores, podemos finalmente treinar nosso classificador de spam / ham. Agora, podemos realmente usar quase qualquer tipo de algoritmos de classificação. Para uma [variedade de razões](http://www.inf.ed.ac.uk/teaching/courses/inf2b/learnnotes/inf2b-learn-note07-2up.pdf), o algoritmo do classificador Naive Bayes é uma boa escolha ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nós estaremos usando scikit-learn aqui, escolhendo o classificador [Naive Bayes](http://en.wikipedia.org/wiki/Naive_Bayes_classifier) para começar com:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_detect_model = MultinomialNB().fit(messages_tfidf, messages['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos tentar classificar nossa única mensagem aleatória e verificar como performamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: ham\n",
      "expected: ham\n"
     ]
    }
   ],
   "source": [
    "print('predicted:', spam_detect_model.predict(tfidf4)[0])\n",
    "print('expected:', messages.label[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantástico! Nós desenvolvemos um modelo que pode tentar prever a classificação de spam vs. classificação de presunto!\n",
    "\n",
    "## Parte 6: Avaliação do Modelo\n",
    "Agora, queremos determinar o quão bem o nosso modelo irá performar em geral em todo o conjunto de dados. Comecemos obtendo todas as previsões:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'spam' ... 'ham' 'ham' 'ham']\n"
     ]
    }
   ],
   "source": [
    "all_predictions = spam_detect_model.predict(messages_tfidf)\n",
    "print(all_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar o relatório de classificação incorporado do SciKit Learn, que retorna [precisão, recall,](https://en.wikipedia.org/wiki/Precision_and_recall) [f1-score](https://en.wikipedia.org/ wiki / F1_score) e uma coluna de suporte (significando quantos casos suportaram essa classificação). Confira os links para informações mais detalhadas sobre cada uma dessas métricas e a figura abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/700px-Precisionrecall.svg.png' width=400 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99      4825\n",
      "        spam       1.00      0.85      0.92       747\n",
      "\n",
      "    accuracy                           0.98      5572\n",
      "   macro avg       0.99      0.92      0.95      5572\n",
      "weighted avg       0.98      0.98      0.98      5572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(messages['label'], all_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem algumas métricas possíveis para avaliar o desempenho do modelo. O que é o mais importante depende da tarefa e dos efeitos comerciais das decisões baseadas no modelo. Por exemplo, o custo de prever \"spam\" como \"ham\" é provavelmente muito inferior ao de prever \"ham\" como \"spam\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão treino-teste\n",
    "\n",
    "Na \"avaliação\" acima, avaliamos a precisão nos mesmos dados que usamos para treinamento. ** Você nunca deve realmente avaliar no mesmo conjunto de dados em que você treina! **\n",
    "\n",
    "Essa avaliação não nos diz nada sobre o verdadeiro poder preditivo de nosso modelo. Se simplesmente nos lembrássemos de cada exemplo durante o treinamento, a precisão dos dados de treinamento seria trivialmente 100%, mesmo que não possamos classificar as novas mensagens.\n",
    "\n",
    "Uma maneira adequada é dividir os dados em um conjunto de treinamento / teste, onde o modelo só vê os ** dados de treinamento ** durante a montagem do modelo e o ajuste de parâmetros. Os ** dados de teste ** nunca são usados de forma alguma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4457 1115 5572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "msg_train, msg_test, label_train, label_test = \\\n",
    "train_test_split(messages['message'], messages['label'], test_size=0.2)\n",
    "\n",
    "print(len(msg_train), len(msg_test), len(msg_train) + len(msg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O tamanho do teste é de 20% do conjunto de dados inteiro (1115 mensagens do total de 5572), e o treinamento é o restante (4457 de 5572). Observe que a divisão padrão teria sido 30/70.\n",
    "\n",
    "## Criando um pipeline de dados\n",
    "\n",
    "Vamos executar o nosso modelo novamente e depois prever o conjunto de testes. Usaremos os recursos [pipeline](http://scikit-learn.org/stable/modules/pipeline.html) do SciKit Learn para armazenar uma linha de fluxo de trabalho. Isso nos permitirá configurar todas as transformações que faremos aos dados para uso futuro. Vejamos um exemplo de como funciona:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # Tokeniza as mensagens\n",
    "    ('tfidf', TfidfTransformer()),  # Faz a transformação em TF-IDF\n",
    "    ('classifier', MultinomialNB()),  # Define a classe que realizará nossa classificação.\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, podemos passar diretamente os dados de texto da mensagem e o pipeline fará o nosso pré-processamento para nós! Podemos tratá-lo como uma API modelo / estimador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('bow',\n",
       "                 CountVectorizer(analyzer=<function text_process at 0x000001A6AC8E0048>,\n",
       "                                 binary=False, decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('classifier',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(msg_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      0.96      0.98      1017\n",
      "        spam       0.70      1.00      0.82        98\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.85      0.98      0.90      1115\n",
      "weighted avg       0.97      0.96      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions,label_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a classification report for our model on a true testing set! There is a lot more to Natural Language Processing than what we've covered here, and its vast expanse of topic could fill up several college courses! I encourage you to check out the resources below for more information on NLP!\n",
    "\n",
    "Agora, temos um relatório de classificação para o nosso modelo em um verdadeiro conjunto de testes! Há muito mais para se explorar no processamento de linguagem natural além do que cobrimos aqui, e sua vasta extensão de tópicos pode preencher vários cursos universitários! Eu encorajo você a verificar os recursos abaixo para obter mais informações sobre a PNL!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mais recursos\n",
    "\n",
    "Confira os links abaixo para mais informações sobre Processamento de linguagem natural:\n",
    "\n",
    "[NLTK Book Online](http://www.nltk.org/book/)\n",
    "\n",
    "[Kaggle Walkthrough](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words)\n",
    "\n",
    "[SciKit Learn's Tutorial](http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
